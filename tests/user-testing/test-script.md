# User Testing Script

## Facilitator Guide

This script provides a structured approach for conducting moderated usability testing sessions. Follow this guide to ensure consistent, effective testing across all participants.

---

## Pre-Session Setup (15 minutes before)

### Technical Setup
- [ ] Test recording software (Zoom, Lookback, etc.)
- [ ] Ensure stable internet connection
- [ ] Open testing platform in browser
- [ ] Prepare note-taking document
- [ ] Test audio and video quality
- [ ] Have backup recording method ready

### Materials Checklist
- [ ] Consent form
- [ ] Task scenarios printed/ready
- [ ] Observation checklist
- [ ] Post-test survey link
- [ ] Compensation information
- [ ] Contact information for follow-up

---

## Session Script (60 minutes total)

### Introduction (5 minutes)

**Facilitator**: "Hi [Name], thank you so much for joining me today. My name is [Your Name], and I'll be guiding you through this session. Before we begin, I want to explain what we'll be doing today and answer any questions you might have."

**Explain Purpose**:
"We're testing a new AI platform for mushroom cultivators called Crowe Logic AI. The goal today is to understand how people like you interact with the platform, what works well, and what could be improved. I want to emphasize that we're testing the product, not you. There are no right or wrong answers, and any difficulties you encounter are valuable feedback for us."

**Explain Think-Aloud Protocol**:
"As you use the platform, I'd like you to think out loud - tell me what you're looking at, what you're thinking, what you're trying to do. This helps me understand your thought process. It might feel a bit awkward at first, but it's incredibly helpful for us."

**Example**: "For instance, if you were looking for a button, you might say 'I'm looking for a way to upload an image... I see a button here that says Upload... I'm going to click that.'"

**Explain Recording**:
"With your permission, I'd like to record this session so our team can review it later. The recording will only be used internally and will not be shared publicly. Is that okay with you?"

**Get Consent**:
"Great. I have a consent form here that covers what we just discussed. [Share consent form] Please take a moment to read through it, and let me know if you have any questions."

[Wait for participant to read and sign consent form]

**Any Questions?**:
"Do you have any questions before we begin?"

---

### Background Questions (5 minutes)

**Facilitator**: "Before we start with the tasks, I'd like to learn a bit about you and your experience with mushroom cultivation."

**Questions**:

1. **Experience Level**
   - "How long have you been growing mushrooms?"
   - "What species do you typically grow?"
   - "Are you growing for personal use, commercially, or research?"

2. **Current Challenges**
   - "What are the biggest challenges you face in your cultivation practice?"
   - "How do you currently solve problems or find information?"
   - "Have you used any other cultivation tools or platforms?"

3. **Technology Comfort**
   - "How comfortable are you with using web applications?"
   - "Have you used AI tools before? If so, which ones?"
   - "What devices do you typically use? (Desktop, mobile, tablet)"

4. **Goals and Expectations**
   - "What would you hope to get from an AI cultivation assistant?"
   - "What features would be most valuable to you?"

**Facilitator**: "Thank you for sharing that. Now let's move on to the tasks."

---

### Task 1: First Impressions (5 minutes)

**Facilitator**: "I'm going to show you the homepage of Crowe Logic AI. I'd like you to take a look at it and tell me your first impressions. Don't click anything yet, just look and tell me what you see."

[Share screen with homepage]

**Probing Questions**:
- "What is this website about?"
- "Who do you think this is for?"
- "What can you do here?"
- "What stands out to you?"
- "Is there anything confusing?"
- "Does this look trustworthy to you? Why or why not?"

**Observation Notes**:
- [ ] User understands platform purpose
- [ ] User identifies key features
- [ ] User expresses interest/skepticism
- [ ] User notices specific elements
- [ ] User has questions or concerns

**Facilitator**: "Great, thank you. Now you can interact with the page."

---

### Task 2: Contamination Analysis (10 minutes)

**Scenario**: "Imagine you've noticed some unusual growth in your substrate. You're not sure if it's contamination or just normal mycelium growth. You want to use Crowe Logic AI to help identify what's going on."

**Task**: "Using this platform, try to get help identifying whether you have contamination. I have a sample image you can use."

[Provide sample contamination image]

**Let User Attempt Task**

**Observation Points**:
- [ ] How does user navigate to upload feature?
- [ ] Does user find the right feature?
- [ ] How long does it take?
- [ ] Does user hesitate or get confused?
- [ ] Does user read instructions?

**If User Struggles (after 2 minutes)**:
- "What are you looking for right now?"
- "Where would you expect to find that?"
- "What would you try next?"

**After Upload**:
- "What do you think of the AI's response?"
- "Is this helpful? Why or why not?"
- "What would you do with this information?"
- "Is there anything missing?"

**Success Criteria**:
- [ ] User finds upload feature
- [ ] User successfully uploads image
- [ ] User receives AI analysis
- [ ] User understands the diagnosis
- [ ] User knows next steps

---

### Task 3: Finding Information (8 minutes)

**Scenario**: "You're interested in growing Lion's Mane mushrooms for the first time. You want to learn about the specific growing parameters and requirements."

**Task**: "Find information about growing Lion's Mane mushrooms, including temperature, humidity, and substrate requirements."

**Let User Attempt Task**

**Observation Points**:
- [ ] Does user use search?
- [ ] Does user browse navigation?
- [ ] Does user find species library?
- [ ] How long does it take?
- [ ] Does user find complete information?

**Probing Questions**:
- "Is this the information you were looking for?"
- "Is anything missing?"
- "How would you save this for later?"
- "Would you trust this information? Why?"

**Success Criteria**:
- [ ] User finds Lion's Mane information
- [ ] User locates growing parameters
- [ ] User understands the information
- [ ] User can save/bookmark

---

### Task 4: AI Chat Interaction (10 minutes)

**Scenario**: "You have a specific question about substrate preparation. You want to ask the AI for advice."

**Task**: "Ask the AI about the best substrate recipe for oyster mushrooms."

**Let User Attempt Task**

**Observation Points**:
- [ ] Does user find chat feature?
- [ ] How does user phrase question?
- [ ] Does user understand response?
- [ ] Does user ask follow-up questions?
- [ ] Does user trust the AI?

**Probing Questions**:
- "What do you think of the AI's response?"
- "Does this answer your question?"
- "How does this compare to other sources?"
- "Would you follow this advice?"

**Follow-up Task**:
"Now ask a follow-up question based on the AI's response."

**Observation Points**:
- [ ] User continues conversation naturally
- [ ] User references previous context
- [ ] AI maintains context
- [ ] User is satisfied with interaction

**Success Criteria**:
- [ ] User finds chat feature
- [ ] User asks clear question
- [ ] User receives helpful response
- [ ] User successfully continues conversation

---

### Task 5: Pricing Exploration (7 minutes)

**Scenario**: "You're considering using Crowe Logic AI regularly and want to understand the pricing options."

**Task**: "Explore the pricing options and decide which tier would be best for your needs."

**Let User Attempt Task**

**Observation Points**:
- [ ] Does user find pricing page?
- [ ] Does user compare tiers?
- [ ] Does user understand differences?
- [ ] Does user identify value?
- [ ] Does user have concerns?

**Probing Questions**:
- "Which tier are you leaning towards? Why?"
- "What features are most important to you?"
- "Is the pricing clear?"
- "Is this good value for money?"
- "What would make you upgrade?"
- "What concerns do you have?"

**Success Criteria**:
- [ ] User finds pricing page
- [ ] User understands tier differences
- [ ] User identifies appropriate tier
- [ ] User feels confident in decision

---

### General Exploration (5 minutes)

**Facilitator**: "Now I'd like you to explore the platform freely. Look around, click on things that interest you, and tell me what you're thinking."

**Let User Explore**

**Observation Points**:
- [ ] What features does user explore?
- [ ] What catches user's attention?
- [ ] What does user ignore?
- [ ] What questions does user have?
- [ ] What delights or frustrates user?

**Probing Questions**:
- "What are you curious about?"
- "What would you want to try next?"
- "Is there anything you expected to see but didn't?"

---

### Post-Test Questions (10 minutes)

**Facilitator**: "Thank you for working through those tasks. Now I'd like to ask you some questions about your overall experience."

**Overall Impression**:
1. "What's your overall impression of Crowe Logic AI?"
2. "On a scale of 1-5, how satisfied are you with the platform?"
3. "What did you like most about it?"
4. "What was most frustrating or confusing?"

**Specific Features**:
5. "What did you think of the AI chat feature?"
6. "What did you think of the contamination analysis?"
7. "What did you think of the visual design?"
8. "What did you think of the navigation?"

**Comparison**:
9. "How does this compare to other tools you've used?"
10. "What makes this better or worse?"
11. "What would make you choose this over alternatives?"

**Trust and Credibility**:
12. "Do you trust the AI's recommendations? Why or why not?"
13. "What makes this platform credible to you?"
14. "What would increase your trust?"

**Value Proposition**:
15. "Would you use this platform? Why or why not?"
16. "Would you pay for this? Which tier?"
17. "Would you recommend this to other cultivators?"

**Improvements**:
18. "If you could change one thing, what would it be?"
19. "What features are missing?"
20. "What would make this a must-have tool for you?"

---

### System Usability Scale (5 minutes)

**Facilitator**: "I have a short survey with 10 statements. For each one, please tell me how much you agree or disagree on a scale of 1 to 5, where 1 is Strongly Disagree and 5 is Strongly Agree."

**SUS Questions**:
1. I think I would like to use this system frequently
2. I found the system unnecessarily complex
3. I thought the system was easy to use
4. I think I would need support to use this system
5. I found the various functions well integrated
6. I thought there was too much inconsistency
7. I would imagine most people would learn quickly
8. I found the system very cumbersome to use
9. I felt very confident using the system
10. I needed to learn a lot before I could get going

---

### Net Promoter Score (1 minute)

**Facilitator**: "One final question: On a scale of 0 to 10, how likely are you to recommend Crowe Logic AI to a friend or colleague who grows mushrooms?"

[Record score]

**Follow-up**: "What's the main reason for your score?"

---

### Closing (2 minutes)

**Facilitator**: "That's all the questions I have. Thank you so much for your time and feedback today. Your insights are incredibly valuable and will help us improve the platform."

**Compensation**:
"As a thank you, [explain compensation - gift card, payment, etc.]"

**Follow-up**:
"We may have follow-up questions as we analyze the data. Would it be okay to contact you if needed?"

**Final Thoughts**:
"Do you have any final thoughts or questions for me?"

**Thank You**:
"Thank you again for your time. Have a great day!"

[End recording]

---

## Post-Session Tasks

### Immediate (within 1 hour)
- [ ] Save and backup recording
- [ ] Review and expand notes
- [ ] Document key quotes
- [ ] Note critical issues
- [ ] Rate severity of issues

### Within 24 hours
- [ ] Transcribe key sections
- [ ] Create highlight reel
- [ ] Update findings document
- [ ] Share critical issues with team
- [ ] Send thank you email to participant

### Within 1 week
- [ ] Complete full analysis
- [ ] Add to aggregate data
- [ ] Update recommendations
- [ ] Share insights with team

---

## Tips for Facilitators

### Do's
✅ Be neutral and non-judgmental
✅ Let users struggle (briefly) before helping
✅ Ask open-ended questions
✅ Probe for deeper understanding
✅ Take detailed notes
✅ Thank users frequently
✅ Stay on schedule

### Don'ts
❌ Lead users to answers
❌ Defend the design
❌ Interrupt users
❌ Ask yes/no questions
❌ Make assumptions
❌ Rush through tasks
❌ Show frustration

### Probing Techniques

**When user is silent**:
- "What are you thinking?"
- "Tell me what you're looking at"

**When user is confused**:
- "What were you expecting?"
- "Where would you look for that?"

**When user succeeds**:
- "Was that what you expected?"
- "How did you know to do that?"

**When user fails**:
- "What would you try next?"
- "How would you solve this?"

### Body Language

- Maintain neutral expression
- Nod to encourage talking
- Lean forward to show interest
- Avoid crossing arms
- Make eye contact (but don't stare)
- Smile warmly

---

## Emergency Protocols

### Technical Issues
- Have backup recording method
- Have backup device ready
- Know how to share screen
- Have participant's phone number

### Participant Issues
- If participant is uncomfortable, pause or end session
- If participant is hostile, end session professionally
- If participant is off-topic, gently redirect
- If participant is too quiet, encourage more

### Time Management
- If running over, skip general exploration
- If running under, add more probing questions
- Always complete post-test survey
- Always get NPS score

---

This script ensures consistent, professional user testing sessions that generate valuable insights for improving the Crowe Logic AI platform.
