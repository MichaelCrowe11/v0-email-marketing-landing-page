# AI Orchestration - Project Structure

## New Directory Structure

```
your-project/
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ kv/                              # Vercel KV Infrastructure
â”‚   â”‚   â”œâ”€â”€ client.ts                    # KV client & key management
â”‚   â”‚   â”œâ”€â”€ rate-limit.ts                # Distributed rate limiting (4 tiers)
â”‚   â”‚   â”œâ”€â”€ cache.ts                     # Semantic + exact caching
â”‚   â”‚   â””â”€â”€ deduplication.ts             # Request deduplication
â”‚   â”‚
â”‚   â””â”€â”€ ai/                              # AI Orchestration Layer
â”‚       â”œâ”€â”€ orchestrator.ts              # Main unified AI handler
â”‚       â”œâ”€â”€ router.ts                    # Intelligent model selection
â”‚       â”œâ”€â”€ retry.ts                     # Exponential backoff + circuit breaker
â”‚       â”œâ”€â”€ fallback.ts                  # Health monitoring + failover
â”‚       â””â”€â”€ observability.ts             # Token tracking & analytics
â”‚
â”œâ”€â”€ app/api/ai/v2/                       # New Enhanced API Endpoints
â”‚   â”œâ”€â”€ chat/route.ts                    # Full orchestration chat
â”‚   â”œâ”€â”€ route-suggest/route.ts           # Model recommendations
â”‚   â”œâ”€â”€ health/route.ts                  # System health check
â”‚   â””â”€â”€ usage/route.ts                   # User usage statistics
â”‚
â””â”€â”€ docs/                                # Documentation
    â”œâ”€â”€ AI_ORCHESTRATION_UPGRADE.md      # Complete technical guide
    â”œâ”€â”€ VERCEL_KV_SETUP.md               # KV setup instructions
    â”œâ”€â”€ IMPLEMENTATION_SUMMARY.md        # Executive summary
    â””â”€â”€ PROJECT_STRUCTURE.md             # This file
```

## Feature Mapping

### Rate Limiting (`lib/kv/rate-limit.ts`)
- 4 subscription tiers (Free, Pro, Expert, Master)
- Per-model rate limits
- Penalty system for abuse
- Distributed across Vercel regions

### Caching (`lib/kv/cache.ts`)
- Exact match caching
- Semantic similarity matching
- Smart TTL selection
- Cache statistics

### Deduplication (`lib/kv/deduplication.ts`)
- Request fingerprinting
- In-flight request detection
- Duplicate prevention
- Cost savings tracking

### Orchestrator (`lib/ai/orchestrator.ts`)
- Unified AI request interface
- All features integrated
- Streaming support
- Batch processing

### Router (`lib/ai/router.ts`)
- 9 task type classifications
- Complexity analysis
- Budget-aware routing
- Model recommendations

### Retry Logic (`lib/ai/retry.ts`)
- Exponential backoff
- Circuit breaker
- Retryable error detection
- Model-specific configs

### Fallback System (`lib/ai/fallback.ts`)
- Health monitoring
- Automatic failover
- Configurable chains
- Recovery tracking

### Observability (`lib/ai/observability.ts`)
- Token usage tracking
- Performance metrics (latency, p95, p99)
- Daily/monthly aggregates
- GDPR compliance (export/delete)

## API Endpoint Flow

```
Client Request
      â†“
/api/ai/v2/chat
      â†“
Orchestrator
      â†“
â”œâ”€â†’ Rate Limit Check
â”œâ”€â†’ Cache Lookup
â”œâ”€â†’ Deduplication
â”œâ”€â†’ Smart Routing
â”œâ”€â†’ Model Request (with retry & fallback)
â”œâ”€â†’ Cache Response
â””â”€â†’ Track Usage
      â†“
Response to Client
```

## Configuration Files

### Environment Variables
```
.env.local
â”œâ”€â”€ KV_URL                      # Vercel KV connection
â”œâ”€â”€ KV_REST_API_URL             # REST API endpoint
â”œâ”€â”€ KV_REST_API_TOKEN           # Auth token
â”œâ”€â”€ OPENAI_API_KEY              # OpenAI
â”œâ”€â”€ ANTHROPIC_API_KEY           # Anthropic
â””â”€â”€ GOOGLE_GENERATIVE_AI_API_KEY # Google
```

### Rate Limit Config
```typescript
// lib/kv/rate-limit.ts
RATE_LIMIT_TIERS = {
  free: 10 req/min
  pro: 50 req/min
  expert: 200 req/min
  master: 1000 req/min
}
```

### Cache Config
```typescript
// lib/kv/cache.ts
CACHE_TTL = {
  SHORT: 5 minutes
  MEDIUM: 30 minutes
  LONG: 1 hour
  VERY_LONG: 24 hours
}
```

### Fallback Config
```typescript
// lib/ai/fallback.ts
FALLBACK_CHAINS = {
  'openai/gpt-4o': ['openai/gpt-4o-mini', 'anthropic/claude-3-5-sonnet']
  'anthropic/claude-3-5-sonnet': ['openai/gpt-4o', 'google/gemini-1.5-pro']
  // ... more chains
}
```

## Code Statistics

```
Component              Files  Lines  Features
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
KV Infrastructure        4    1,150  Rate limiting, caching, dedup
AI Orchestration         5    1,457  Routing, retry, fallback, metrics
API Endpoints            4      450  Chat, health, usage, routing
Documentation            3    3,500  Complete guides & references
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total                   16    6,557  7 major features
```

## Integration Points

### Existing Code
```
app/api/chat/route.ts           â†’ Can migrate to orchestrator
app/api/ai/stream/route.ts      â†’ Can use new caching
components/chat/                 â†’ Can integrate v2 endpoints
```

### Database Integration
```
Supabase Tables:
â”œâ”€â”€ users                        â†’ Rate limit tier lookup
â”œâ”€â”€ subscriptions                â†’ Tier mapping
â””â”€â”€ usage_tracking               â†’ Optional: sync with KV metrics
```

### Monitoring
```
Vercel Dashboard:
â”œâ”€â”€ KV Storage                   â†’ Monitor usage & keys
â”œâ”€â”€ Function Logs                â†’ Track errors
â””â”€â”€ Analytics                    â†’ Request patterns
```

## Migration Strategy

### Phase 1: Deploy Infrastructure (Week 1)
- Deploy KV infrastructure
- Add v2 endpoints alongside v1
- Test with internal users

### Phase 2: Gradual Rollout (Week 2-3)
- Route 10% traffic to v2
- Monitor metrics
- Increase to 50% traffic

### Phase 3: Full Migration (Week 4)
- Route 100% traffic to v2
- Deprecate v1 endpoints
- Monitor for 1 week

### Phase 4: Optimization (Ongoing)
- Tune cache TTLs
- Adjust rate limits
- Refine model routing

## Quick Start Commands

```bash
# 1. Install dependencies
npm install @vercel/kv

# 2. Setup Vercel KV
vercel login
vercel link
vercel env pull .env.local

# 3. Test locally
npm run dev

# 4. Deploy
git add .
git commit -m "feat: AI orchestration upgrade"
git push origin main
```

## Testing Endpoints

```bash
# Health check
curl https://your-app.vercel.app/api/ai/v2/health

# Chat request
curl -X POST https://your-app.vercel.app/api/ai/v2/chat \
  -H "Content-Type: application/json" \
  -d '{"messages": [{"role": "user", "content": "Hello"}]}'

# Model suggestion
curl -X POST https://your-app.vercel.app/api/ai/v2/route-suggest \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Solve this complex problem"}'

# Usage stats
curl https://your-app.vercel.app/api/ai/v2/usage
```

## Support Resources

### Documentation
- [AI_ORCHESTRATION_UPGRADE.md](./AI_ORCHESTRATION_UPGRADE.md) - Full technical details
- [VERCEL_KV_SETUP.md](./VERCEL_KV_SETUP.md) - KV setup guide
- [IMPLEMENTATION_SUMMARY.md](./IMPLEMENTATION_SUMMARY.md) - Executive summary

### Code References
- `lib/kv/` - All KV infrastructure
- `lib/ai/` - All AI orchestration
- `app/api/ai/v2/` - New API endpoints

### External Links
- [Vercel KV Docs](https://vercel.com/docs/storage/vercel-kv)
- [AI SDK Docs](https://sdk.vercel.ai/docs)
- [OpenAI Best Practices](https://platform.openai.com/docs/guides/production-best-practices)

---

**All components are production-ready and fully documented!** ðŸš€
